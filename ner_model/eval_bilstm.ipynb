{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "haskdpB8l0PV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from bilstm import BiLSTM\n",
        "from load_data import num_words, num_tags, words, tags, word2idx, tag2idx, train_X, train_y, test_X, test_y, train_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ziyet\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_model = BiLSTM(num_words, tag2idx, embedding_dim=50, hidden_dim=200)\n",
        "new_model.load_state_dict(torch.load(\"./weights/bilstm.pth\", map_location='cpu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpHJce-El0Pa",
        "outputId": "fab065af-2b97-45c0-b37b-47ab836be4e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "999\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[3], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m cur_X \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(test_X[i:i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m], dtype \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mlong)\n\u001b[0;32m      9\u001b[0m cur_y \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(test_y[i], dtype \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mlong)\n\u001b[1;32m---> 11\u001b[0m pred \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49margmax(new_model(cur_X)[\u001b[39m0\u001b[39;49m], dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     12\u001b[0m TP \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msum((pred\u001b[39m!=\u001b[39mtag2idx[\u001b[39m'\u001b[39m\u001b[39mO\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39m*\u001b[39m (pred \u001b[39m==\u001b[39m cur_y))\n\u001b[0;32m     13\u001b[0m TN \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msum((pred\u001b[39m==\u001b[39mtag2idx[\u001b[39m'\u001b[39m\u001b[39mO\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39m*\u001b[39m (pred \u001b[39m==\u001b[39m cur_y))\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Calculate Precision, Recall, and F1 Score\n",
        "new_model.eval()\n",
        "TP = 0\n",
        "TN = 0\n",
        "FP = 0\n",
        "FN = 0\n",
        "for i in range(len(test_X)):\n",
        "    cur_X = torch.tensor(test_X[i:i+1], dtype = torch.long)\n",
        "    cur_y = torch.tensor(test_y[i], dtype = torch.long)\n",
        "\n",
        "    pred = torch.argmax(new_model(cur_X)[0], dim=1)\n",
        "    TP += torch.sum((pred!=tag2idx['O']) * (pred == cur_y))\n",
        "    TN += torch.sum((pred==tag2idx['O']) * (pred == cur_y))\n",
        "    FP += torch.sum((pred!=tag2idx['O']) * (pred != cur_y))\n",
        "    FN += torch.sum((pred==tag2idx['O']) * (pred != cur_y))\n",
        "    \n",
        "    if (i+1)%1000 == 0:\n",
        "        print(i)\n",
        "\n",
        "prec = TP/(TP+FP)\n",
        "recall = TP/(TP+FN)\n",
        "f1 = prec*recall/(prec+recall)\n",
        "print(\"Precision: \",prec)\n",
        "print(\"Recall: \", recall)\n",
        "print(\"F1 Score: \", f1*2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7dhRbXnNZjn",
        "outputId": "1a527e1a-d7a1-4d7f-e40d-25a95a5bab19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The famine killed as many as 10 million people in what was then Soviet Ukraine .  \n",
            "\n",
            "O O O O O O O O O O O O O O B-geo O  \n",
            "\n",
            "O O O O O O O O O O O O O O B-geo O  \n",
            "\n",
            "\n",
            "Many analysts say the famine was not from natural causes , but instead was the result of government policies under Soviet dictator Josef Stalin .  \n",
            "\n",
            "O O O O O O O O O O O O O O O O O O O O O O B-per I-per O  \n",
            "\n",
            "O O O O O O O O O O O O O O O O O O O O O O B-per I-per O  \n",
            "\n",
            "\n",
            "Ukrainian President Viktor Yushchenko supported the bill .  \n",
            "\n",
            "B-gpe B-per I-per I-per O O O O  \n",
            "\n",
            "B-gpe B-per I-per I-per O O O O  \n",
            "\n",
            "\n",
            "Most have been released unharmed , often after a payment of ransom .  \n",
            "\n",
            "O O O O O O O O O O O O O  \n",
            "\n",
            "O O O O O O O O O O O O O  \n",
            "\n",
            "\n",
            "On Saturday , he spoke in the capital , Kiev , to mark the 73rd anniversary of the tragedy , known in Ukraine as the Holodomor .  \n",
            "\n",
            "O B-tim O O O O O O O B-per O O O O O O O O O O O O B-geo O O B-geo O  \n",
            "\n",
            "O B-tim O O O O O O O B-org O O O O B-tim O O O O O O O B-geo O O O O  \n",
            "\n",
            "\n",
            "China denies it is failing to keep the Olympic Games and politics separate after a Communist party official criticized the Dalai Lama at a torch relay ceremony in Tibet .  \n",
            "\n",
            "B-geo O O O O O O O O O O O O O O O O O O O B-geo I-geo O O O O O O B-geo O  \n",
            "\n",
            "B-geo O O O O O O O O O O O O O O O O O O O B-per I-geo O O O O O O B-geo O  \n",
            "\n",
            "\n",
            "The Chinese foreign ministry Thursday said the official 's comments did not contradict China 's opposition to politicizing the Olympics .  \n",
            "\n",
            "O B-gpe O O B-tim O O O O O O O O B-geo O O O O O O O  \n",
            "\n",
            "O B-gpe O O B-tim O O O O O O O O B-geo O O O O O O O  \n",
            "\n",
            "\n",
            "The ministry said the comments were meant to create a stable environment for the Olympics .  \n",
            "\n",
            "O O O O O O O O O O O O O O O O  \n",
            "\n",
            "O O O O O O O O O O O O O O B-eve O  \n",
            "\n",
            "\n",
            "Earlier Thursday , the International Olympic Committee urged the Beijing Organizing Committee for the Olympic games to make sure such situations do not happen again .  \n",
            "\n",
            "O B-tim O O B-org O B-org O O B-geo I-geo B-org O O O O O O O O O O O O O O  \n",
            "\n",
            "O B-tim O O B-org O B-org O O B-org O B-org O O O O O O O O O O O O O O  \n",
            "\n",
            "\n",
            "The IOC said it regrets that the political statements were made during the closing torch relay ceremony Saturday in Tibet 's capital , Lhasa .  \n",
            "\n",
            "O B-org O O O O O O O O O O O O O O O B-tim O B-geo O O O B-org O  \n",
            "\n",
            "O B-org O O O O O O O O O O O O O O O B-tim O B-geo O O O B-geo O  \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Inference on test set\n",
        "new_model.eval()\n",
        "for i in range(7990, 8000):\n",
        "    cur_X = torch.tensor(test_X[i:i+1])\n",
        "    cur_y = torch.tensor(test_y[i:i+1])\n",
        "\n",
        "    pred = torch.argmax(new_model(cur_X),dim=2)\n",
        "    pred_tag = \"\"\n",
        "    t_tag = \"\"\n",
        "    sentence = \"\"\n",
        "    for j in range(0, len(cur_X[0])):\n",
        "        sentence += words[cur_X[0][j]]+\" \"\n",
        "        t_tag += tags[cur_y[0][j]] + \" \"\n",
        "        pred_tag += tags[pred[0][j]] + \" \"\n",
        "    \n",
        "    print(sentence,'\\n')\n",
        "    print(t_tag,'\\n')\n",
        "    print(pred_tag,'\\n\\n')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
